{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project, Part 1: *Proposal*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Draft a well-formed problem statement relevant to a business problem affecting your team, division, or organization.\n",
    "2. Include the following elements:\n",
    "   - Hypothesis/assumptions\n",
    "   - Goals and success metrics\n",
    "   - Risks or limitations\n",
    "3. Identify at least one relevant internal dataset and confirm that you have (or can get) the right access permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original dataset from https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T\n",
    "- Kaggle dataset and competition from https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000/home\n",
    "- Scientific paper from https://arxiv.org/abs/1803.10417\n",
    "\n",
    "\n",
    "**null hypothesis:** There is no difference between dermatoscopic images of pigmented skin lesions between skin cancer diagnostic categories.\n",
    "\n",
    "**alternative hypothesis:** There is a difference between dermatoscopic images of pigmented skin lesions between skin cancer diagnostic categories.\n",
    "\n",
    "**goals and success:** Correctly classify dermatoscoptic images of pigmented skin lesions into a skin cancer diagnostic category at a probability higher than chance. There are 7 categories, so success metric would need to be 15% or greater.\n",
    "\n",
    "**risks or limitations:** Requires enough sample data in each diagnostic category. Also required enough similarities of images within diagnostic category as well as distinctions between diagnostic categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project, Part 2: *Brief*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis is a crucial step in any data workflow. Create a Jupyter Notebook that explores your data mathematically and visually. Explore features, apply descriptive statistics, look at distributions, and determine how to handle sampling or any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an exploratory data analysis notebook.\n",
    "2. Perform statistical analysis, along with any visualizations.\n",
    "3. Determine how to handle sampling or missing values.\n",
    "4. Clearly identify shortcomings, assumptions, and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ham_df = pd.read_csv(\"./data/HAM10000_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ham_df.shape)\n",
    "display(ham_df.head())\n",
    "display(ham_df.describe(include=\"all\"))\n",
    "display(ham_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The HAM metadata has 10015 rows and 7 columns\n",
    "- There are 7470 lesions, however, some are taken with different magnification and angles resulting in 10,015 images accoridng to the paper. This serves as natural data augmentation\n",
    "- The 7 unique `dx` suggests we are classifying for multiple diseases and not binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null values: \\n\", ham_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_null = ham_df[ham_df['age'].isnull()]\n",
    "age_null.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Although there are NaN and unknown values for patient information. I propose we do not replace or drop values as I am considering not using them as features. These variables serve to show the distribution of data.\n",
    "- The feature would be the images themselves.\n",
    "- This is despite distribution of diagnoses varying with patient information.\n",
    "    - eg. melanoma on areas not exposed to sun (incidence higher in leg for women and back for men) as opposed to akiec (actinic keratoses on face and Bowen's disease in other areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Percentage distribution of target diagnostic values: \\n\", round(ham_df['dx'].value_counts(normalize=True)*100, 2))\n",
    "\n",
    "variables = ['dx', 'dx_type', 'age', 'sex', 'localization']\n",
    "for var in variables:\n",
    "    ham_df[var].value_counts().plot(kind=\"bar\")\n",
    "    plt.title(var)\n",
    "    plt.show();\n",
    "\n",
    "ham_df['age'].plot(kind=\"hist\", bins=15)\n",
    "plt.title(\"age\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dx`\n",
    "    - mostly nv (Melanocytic nevi) as these are benign/non-cancerous\n",
    "    - much less sample data for the others\n",
    "        - need to ensure there are enough sample data to include smaller categories\n",
    "        - when modelling need to consider techniques such as oversampling, stratified folds\n",
    "- `dx_type`\n",
    "    - will be accepting all forms of diagnosis as accurate and not just histogram\n",
    "- `localization`\n",
    "    - in reality, these would vary by `dx` and `sex`\n",
    "    \n",
    "- Target value is `dx_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dx_samples.png\" alt=\"Diagnostic category samples\" title=\"Diagnostic category samples\"/>\n",
    "- From the images we can see that there are visual differences within categories\n",
    "    - this is because they are categorised by biology\n",
    "    - for example, `vasc` includes angiomas, angioketaomas, pyogenic granulomas and haemorrahge and therefore presentations may vary\n",
    "    - in `blk`, a subset within (linchen-planus like keratoses) have features that are similar to `mel` and therefore ML may incorrectly classify these scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next Steps**\n",
    "- load and process data into `ham_df`\n",
    "- use `hmnist` file and/or learn how images can be processed into data\n",
    "- test train split\n",
    "- start with a simple model\n",
    "- read and find out what models are available and test these\n",
    "- explore errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project, Part 3: *Technical Notebook*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a prototype model or process to successfully resolve the business problem you've chosen. Document your work in a technical notebook that can be shared with your peers.\n",
    "\n",
    "Build upon your earlier analysis, folling the performance metrics you established as part of your problem's evaluation criteria. Demonstrate your approach logically, including all relevant code and data. Polish your notebook for peer audiences by cleanly formatting sections, headers, and descriptions in markdown. Include comments in any code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A detailed Jupyter Notebook with a summary of your analysis, approach, and evaluation metrics.\n",
    "2. Clearly formatted structure with section headings and markdown descriptions.\n",
    "3. Comments explaining your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os \n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "ham_df = pd.read_csv(\"./data/HAM10000_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to Kevin Mader for code\n",
    "base_skin_dir = os.path.join(\".\", \"data\")\n",
    "\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
    "\n",
    "ham_df['path'] = ham_df['image_id'].map(imageid_path_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placing label (diagnosis) into the name of image file\n",
    "for dx, filename in zip(ham_df['dx'], ham_df['path']):\n",
    "    path = filename[0:30]\n",
    "    image_id = filename[-12:]\n",
    "    os.rename(filename, path+dx+image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the image files are currently stored\n",
    "path_1 = \"./data/HAM10000_images_part_1\"\n",
    "path_2 = \"./data/HAM10000_images_part_2\"\n",
    "\n",
    "# Create a new directory to store all images\n",
    "os.mkdir(\"./data/images\")\n",
    "\n",
    "# Function to move files to this image directory\n",
    "def move_files(path):\n",
    "    src_files = os.listdir(path)\n",
    "    for filename in src_files:\n",
    "        full_filename = os.path.join(path, filename)\n",
    "        if (os.path.isfile(full_filename)):\n",
    "            shutil.copy(full_filename, \"./data/images/\"+filename)\n",
    "   \n",
    "move_files(path_1)\n",
    "move_files(path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://course.fast.ai/setup/colab | bash\n",
    "\n",
    "%reload_ext_autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "import re\n",
    "import numpy as np\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = \"./data/images/\"\n",
    "fnames = get_image_files(path_img) # grabs array of image files\n",
    "fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # sets same validation set\n",
    "pat = re.compile(r'/([^/]+)_\\d+.jpg$') # applies regex to obtain label\n",
    "tfns = get_transforms(flip_vert=True, # this with default allows 8 symmetric dihedral rots/flips\n",
    "                      max_lighting=0.1,\n",
    "                      max_zoom=1.05\n",
    "                      max_warp=0.1) # perspective warping\n",
    "\n",
    "# ImageDataBunch contains contains train, validation (and optional test)\n",
    "data = ImageDataBunch.from_name_re(path_img, # path with images\n",
    "                                   fnames, # filenames\n",
    "                                   pat, # regex\n",
    "                                   valid_pct=0.2 # randomly sets aside 20% for validation\n",
    "                                   ds_tfms=tfms, # data augmentation\n",
    "                                   size=224, # image size\n",
    "                                   bs=64) # value depends on gpu\n",
    "data.normalize(imagenet_stats) # pixel values of RGB to have mean 0 and std 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=4, figsize=(9,9)) # show some contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes # there are 7 classes (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = ConvLearner(data, models.resnet34, metrics=error_rate)\n",
    "# Create convolutional neural net with pretrained weights from imagenet\n",
    "learn = create_cnn(data, \n",
    "                   models.resnet34, # architecture - use models.resnet50 for larger\n",
    "                   metrics=error_rate) # error rate (1 - accuracy) against validation set\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.recorder.plot() # find the biggest downward slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = ?\n",
    "# learn.fit_one_cycle(4,slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, 3e-3) #  goes through dataset 4 times\n",
    "# There is 78-79% accuracy as is\n",
    "# Total time: 03:20\n",
    "# epoch\ttrain_loss\tvalid_loss\terror_rate\n",
    "# 1\t1.169474\t0.753518\t0.260110\n",
    "# 2\t0.739373\t0.644836\t0.231653\n",
    "# 3\t0.627650\t0.591759\t0.216675\n",
    "# 4\t0.576652\t0.576550\t0.212681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learning rate is too high, valid loss will become very high. Usually < 1\n",
    "if learning rate is too low, error rate improves very slowly\n",
    "can try learn.recorder.plot_losses() go down very slow\n",
    "also training loss will be higher than valid loss. \n",
    "we never want training loss higher than valid loss. it means we haven't fitted enough.\n",
    "therefore, increase epoch or increase learning rate\n",
    "if epoch is too low, training loss is much higher than valid loss\n",
    "if epoch is too high, it will overfit. error rate will improve then get worse\n",
    "* training loss should be lower than valid loss. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"stage-1\") # save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn) # interpret data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12)) \n",
    "# diags are correct. dark areas outside diagonals are incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2) # pred and actual that got wrong most often\n",
    "# should have predicted mel but predicted nv, happened 122 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune\n",
    "learn.unfreeze() # unfreeze rest of model so we can train the whole model\n",
    "# learn.fit_one_cycle(1)\n",
    "# Accuracy improved by 2% only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot() # find before it goes up, and minus 10x for first. second is lr/5 or lr/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, # epoch ?increase \n",
    "                    max_lr=slice(3e-6,# choose number with strongest slope\n",
    "                                 3e-4)) #train early layers at 1e-6, last layers at 1e-4\n",
    "3e-5,3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"stage-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"stage-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = ImageDataBunch.single_from_classes(path_img,\n",
    "                                           fnames,\n",
    "                                           pat,\n",
    "                                           ds_tfms=tfms,\n",
    "                                           size=224).normalize(imagenet_stats)\n",
    "learn = create_cnn(data2, model.resnet34)\n",
    "learn.load(\"stage-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class, pred_idx, outputs = learn.predict(img)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find() # find optimal learning rate ie. how quickly is it updating parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot() # select value before it starts to increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, \n",
    "                    max_lr=slice(1e-6,1e-4) #train early layers at 1e-6, last layers at 1e-4\n",
    "                   )\n",
    "# About 80% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
